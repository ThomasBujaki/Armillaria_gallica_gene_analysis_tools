\documentclass[../main.tex]{subfiles}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%	Analysis Methods
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This section will be a in-depth explanation of all methods used over the course of this class. For all programs discussed here see \url{https://github.com/ofbujak/Armillaria_gallica_gene_analysis_tools}.

\subsection{Read Depth Snapshots}%done draft - needs editing/reviewing
	The first work completed was the analysis of the read depth values for each of the 15 sequenced strains of the \textit{Armillaria gallica}. This work was based on analysis which a former student, Hao Wang, had done previously to determine locations for each strain that had unusually high read depth. These locations are based on reads aligned to a reference. Unfortunally, we do not know the exact method which Hao had used to determine which locations he had deemed had significant read depth. Though we do not know the exact method he used, the regions he identified were those that had high read depth. He outputted his results into text files consisting of three columns, a scaffold number column, a location start column, and a location end column. These files had variable numbers of locations of high significance but they averaged approximatly 2636 locations per strain. With the goal to produce graphs of these locations of high read depth, in order to gain a understainding of the "landscape" about those locations, I first made up of the samtools \textit{depth} command in a program called make\_read\_depth\_files.sh

make\_read\_depth\_files.sh will output a file which has three columns, scaffold, location, and read depth. Using these results I wrote a program, read\_depth\_per\_location.c, which will take in as arguments a specific samtools read depth file, a scaffold to search for, a start and end location (all space separated). read\_depth\_per\_location.c will then print information (scaffold, location, read depth, etc...) on the locations, incrementing by 1 from the start location, for all locations which are within the range passed into it. This program was used in plot\_all\_read\_depths.sh to produce graphs of each range of locations with high read depth $\pm$ 500. The program used to create the graphs was plot\_read\_depth.R. Some examples of these graphs can be found in figures \ref{avg_rd_snpsht_1} and \ref{avg_rd_snpsht_2}.
	
\subsection{Read Depths For Whole Scaffolds}
	In order to produce depictions of the read depths for an entire scaffold the framework established to create the read depth snapshots was used with some slight changes in methodology. To produce these graphs the files produces from using the samtools \textit{depth} command were searched via grep in order to separate each scaffold result into its own file. These files were then passed into plot\_scaffold\_read\_depth.R and plot\_scaffold\_read\_depth\_histogram.R. plot\_scaffold\_read\_depth.R is a program which graphs the read depth on the y axis and the location of that read depth on the x axis. plot\_scaffold\_read\_depth\_histogram.R creates a histogram of the read depths with binwidths of 5. %The results for these section can be found in section \ref

\subsection{Read Depth Analyses}
	In order to gain insight into the different aspects of the scaffolds and the reads which were aligned I produced four metrics for each strain. I calculated the global average read depths, determined the total number of sites with reads aligned to them, calculated and graphed the average number of reads per scaffold, and graphed and determined the number of locations with reads aligned for each scaffold. 

\subsection{Unaligned Reads}
	To output all reads which are not aligned into a sam file the following samtools view command can be used: samtools view -f 4 file.bam $>$ unmapped.sam. Following this The reads can be assembled via a de novo assembler. (The assembly of these has not been carried out yet).

\subsection{New Assemblies}
	To produce new assemblies I attempted to do both \textit{de novo} assemblies of five of the strains (Ar170, Ar174, Ar179, Ar196, Ar213). Following verification of quality using FastQC, both methods were used.

	\subsubsection{De Novo Assemblies}
	To produce new \textit{de novo} assemblies of five of the strains (Ar170, Ar174, Ar179, Ar196, Ar213) were attempted. The program used for the assmeblies was Velvet, with the wrapper VelvetOptimiser used. The command used to run VelvetOptimiser was: 
\begin{verbatim}
'perl VelvetOptimiser.pl -f "-shortPaired -fastq -separate 
<Path To Forward Strand File>/<Forward_strand.fastq.gz> 
<Path To Reverse Strand File>/<Reverse_strand.fastq.gz>" -t 32 -s 31 -e 31 
-d <Output Directory>
\end{verbatim}

	\subsubsection{Reference Based Assemblies}
	`To produce another reference based assembly the scipt fastqThroughNovoalign.sh was used.

\subsection{Taking the Consensus of Aligned Read}
	Following identification of locations where read depth is significant it was useful to be able to quickly get the actual DNA sequence which is aligned to a specific location. To do this, custom programs were created to sort through the output from samtools view and to take the consensus of the reads aligned. The total pipeline for these programs is encapsulated within consensus\_reads.sh.
	
	To output sequences that were easier to work with, samtools view was used. The command used was: \begin{verbatim}samtools view -o <output_filename> <bam_file> 
<scaffold_number>:<location_start>-<location_end>\end{verbatim} . This command created a sam file with 11 columns (these columns are explained in the file SAMv1.pdf found in Extra_Documents), five of which are required for the following programs. The five required are: the scaffold or contig which a read is aligned to, the location which the first base in a read is aligned to, the cigar string (\textbf{C}ompact \textbf{I}diosyncratic \textbf{G}apped \textbf{A}lignment \textbf{R}eport) which give information about what bases from the read align to the reference, the actaul read itself, and the quality score for each base in the read. 

	Following outputting of the sam file, the program 'pull\_reads.c' is used. This program takes in the five columns listed above (in the order discussed) and outputs all the reads, which fall within the range specified, into a file where each read occupies its own line with each read offset by the difference between the start of the range of interest and the location which the read starts.
	
	The output created by pull\_reads.c is then passed into average\_reads.c. average\_reads.c takes in the output created by pull\_reads.c and the difference between the start and end locations. This program creates 4 arrays of the size of the difference passed into the program and iterates over all lines in the file. When a base is encounteres at a location the array for that base is incremented by 1, at the location of that base. After all the lines in the file are iterated over, the mode of each base for each element of the array are then output, resulting in a consensus of the reads that were aligned between two locations.

\subsection{Determiation of Regions Of High Read Depth}

\subsection{Compairisons of Read Depths}
	

\subsection{Analysis of DNA Sequences Suspected to Result in High Read Depths}
	Using the locations found to have significant read depth and the method used to take the consensus of the the aligned reads between locations, the sequences at each location which had high read depth could be extracted. After these sequences were extracted they could be searched, via ncbi blastn, to attempt to determine if the sequence has any homologous in other species/ to determine the effect of the sequence.

\subsection{Insertions and Deletions}

	Kassandras stuff here.


\end{document}
